#!/usr/bin/env python3
"""
çœŸå¯¦åœ–ç‰‡å£½å‘½é æ¸¬æ¨¡å‹è¨“ç·´è…³æœ¬

ä½¿ç”¨çœŸå¯¦çš„é¢éƒ¨åœ–ç‰‡ç‰¹å¾µé€²è¡Œå£½å‘½é æ¸¬æ¨¡å‹è¨“ç·´
"""

import sys
import os
import logging
from pathlib import Path
import json
import argparse
from datetime import datetime

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root / "src"))

from ml_pipeline.training.real_image_trainer import train_with_real_images, RealImageDataset, RealImageLifespanTrainer
from ml_pipeline.models.life_prediction.predictor import LifePredictionModel

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(project_root / 'logs' / 'real_image_training.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)


class RealImageTrainingManager:
    """çœŸå¯¦åœ–ç‰‡æ¨¡å‹è¨“ç·´ç®¡ç†å™¨"""

    def __init__(self):
        self.project_root = project_root
        self.data_dir = self.project_root / "data" / "collected" / "wikipedia"
        self.output_dir = self.project_root / "models" / "trained"
        self.image_cache_dir = self.project_root / "data" / "images" / "cache"
        self.logs_dir = self.project_root / "logs"

        # å‰µå»ºå¿…è¦ç›®éŒ„
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.image_cache_dir.mkdir(parents=True, exist_ok=True)
        self.logs_dir.mkdir(parents=True, exist_ok=True)

    def find_latest_dataset(self) -> str:
        """å°‹æ‰¾æœ€æ–°çš„è¨“ç·´è³‡æ–™é›†"""
        try:
            pattern = "mock_training_dataset_*.json"
            dataset_files = list(self.data_dir.glob(pattern))

            if not dataset_files:
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°è¨“ç·´è³‡æ–™æª”æ¡ˆï¼Œæ¨¡å¼: {pattern}")

            # é¸æ“‡æœ€æ–°çš„æª”æ¡ˆ
            latest_file = max(dataset_files, key=lambda x: x.stat().st_mtime)
            logger.info(f"æ‰¾åˆ°æœ€æ–°çš„è¨“ç·´è³‡æ–™æª”æ¡ˆ: {latest_file}")

            return str(latest_file)

        except Exception as e:
            logger.error(f"å°‹æ‰¾è¨“ç·´è³‡æ–™å¤±æ•—: {e}")
            raise

    def get_training_config(self, mode: str = "default") -> dict:
        """ç²å–è¨“ç·´é…ç½®"""
        configs = {
            "quick": {
                'batch_size': 4,  # è¼ƒå°æ‰¹é‡ï¼Œå› ç‚ºåœ–ç‰‡è™•ç†è¼ƒé‡
                'num_epochs': 20,
                'learning_rate': 0.001,
                'weight_decay': 1e-4,
                'patience': 6,
                'min_delta': 0.001,
                'val_split': 0.2,
                'save_best_model': True,
                'plot_training': True
            },
            "default": {
                'batch_size': 8,
                'num_epochs': 50,
                'learning_rate': 0.0005,
                'weight_decay': 1e-4,
                'patience': 10,
                'min_delta': 0.001,
                'val_split': 0.2,
                'save_best_model': True,
                'plot_training': True
            },
            "comprehensive": {
                'batch_size': 16,
                'num_epochs': 100,
                'learning_rate': 0.0003,
                'weight_decay': 1e-5,
                'patience': 15,
                'min_delta': 0.0005,
                'val_split': 0.15,
                'save_best_model': True,
                'plot_training': True
            }
        }

        return configs.get(mode, configs["default"])

    def analyze_real_image_dataset(self, dataset_file: str):
        """åˆ†æçœŸå¯¦åœ–ç‰‡è³‡æ–™é›†"""
        try:
            logger.info("æ­£åœ¨åˆ†æçœŸå¯¦åœ–ç‰‡è¨“ç·´è³‡æ–™é›†...")

            # å‰µå»ºè³‡æ–™é›†å¯¦ä¾‹ï¼ˆé€™æœƒè§¸ç™¼åœ–ç‰‡è™•ç†ï¼‰
            dataset = RealImageDataset(
                data_file=dataset_file,
                image_cache_dir=str(self.image_cache_dir)
            )

            # ç²å–çµ±è¨ˆè³‡è¨Š
            stats = dataset.get_statistics()

            if 'error' in stats:
                logger.error(f"è³‡æ–™é›†åˆ†æå¤±æ•—: {stats['error']}")
                return None

            logger.info("çœŸå¯¦åœ–ç‰‡è³‡æ–™é›†åˆ†æçµæœ:")
            logger.info(f"  æˆåŠŸè™•ç†çš„æ¨£æœ¬æ•¸: {stats['num_samples']}")
            logger.info(f"  é¢éƒ¨ç‰¹å¾µç¶­åº¦: {stats['feature_dim']}")
            logger.info(f"  å‰©é¤˜å£½å‘½çµ±è¨ˆ:")
            label_stats = stats['label_stats']
            logger.info(f"    å¹³å‡: {label_stats['mean']:.1f} å¹´")
            logger.info(f"    æ¨™æº–å·®: {label_stats['std']:.1f} å¹´")
            logger.info(f"    ç¯„åœ: {label_stats['min']:.0f} - {label_stats['max']:.0f} å¹´")

            return dataset, stats

        except Exception as e:
            logger.error(f"çœŸå¯¦åœ–ç‰‡è³‡æ–™é›†åˆ†æå¤±æ•—: {e}")
            return None, None

    def train_model(self, mode: str = "default", dataset_file: str = None) -> dict:
        """åŸ·è¡ŒçœŸå¯¦åœ–ç‰‡æ¨¡å‹è¨“ç·´"""
        try:
            logger.info(f"é–‹å§‹çœŸå¯¦åœ–ç‰‡æ¨¡å‹è¨“ç·´ (æ¨¡å¼: {mode})...")
            start_time = datetime.now()

            # å°‹æ‰¾è³‡æ–™é›†æª”æ¡ˆ
            if dataset_file is None:
                dataset_file = self.find_latest_dataset()

            # åˆ†æè³‡æ–™é›†å’Œè™•ç†åœ–ç‰‡
            dataset, dataset_stats = self.analyze_real_image_dataset(dataset_file)

            if dataset is None:
                return {
                    'success': False,
                    'error': 'è³‡æ–™é›†æº–å‚™å¤±æ•—'
                }

            # ç²å–è¨“ç·´é…ç½®
            config = self.get_training_config(mode)
            logger.info(f"è¨“ç·´é…ç½®: {config}")

            # åŸ·è¡Œè¨“ç·´
            result = train_with_real_images(
                data_file=dataset_file,
                output_dir=str(self.output_dir),
                image_cache_dir=str(self.image_cache_dir),
                config=config
            )

            # è¨ˆç®—ç¸½æ™‚é–“
            end_time = datetime.now()
            training_time = (end_time - start_time).total_seconds()

            if result['success']:
                logger.info("çœŸå¯¦åœ–ç‰‡æ¨¡å‹è¨“ç·´æˆåŠŸå®Œæˆ!")
                logger.info(f"è¨“ç·´æ™‚é–“: {training_time:.1f} ç§’")
                logger.info(f"æœ€ä½³é©—è­‰æå¤±: {result['best_val_loss']:.4f}")
                logger.info(f"æ¨¡å‹å·²ä¿å­˜è‡³: {result.get('model_path', 'N/A')}")

                # æ·»åŠ é¡å¤–è³‡è¨Š
                result.update({
                    'training_time_seconds': training_time,
                    'dataset_stats': dataset_stats,
                    'dataset_file': dataset_file
                })

                # ç”Ÿæˆè¨“ç·´å ±å‘Š
                self._generate_training_report(result)

            else:
                logger.error("çœŸå¯¦åœ–ç‰‡æ¨¡å‹è¨“ç·´å¤±æ•—!")
                logger.error(f"éŒ¯èª¤: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")

            return result

        except Exception as e:
            logger.error(f"çœŸå¯¦åœ–ç‰‡æ¨¡å‹è¨“ç·´éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    def _generate_training_report(self, training_result: dict):
        """ç”Ÿæˆè¨“ç·´å ±å‘Š"""
        try:
            report = {
                'training_timestamp': datetime.now().isoformat(),
                'training_type': 'real_image_features',
                'success': training_result['success'],
                'training_time_seconds': training_result.get('training_time_seconds', 0),
                'dataset_info': {
                    'file': training_result.get('dataset_file'),
                    'stats': training_result.get('dataset_stats', {})
                },
                'model_performance': {
                    'best_val_loss': training_result.get('best_val_loss'),
                    'final_metrics': training_result.get('final_metrics', {})
                },
                'training_config': training_result.get('config', {}),
                'model_path': training_result.get('model_path'),
                'recommendations': self._generate_recommendations(training_result)
            }

            # ä¿å­˜å ±å‘Š
            report_file = self.output_dir / f"real_image_training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)

            logger.info(f"çœŸå¯¦åœ–ç‰‡è¨“ç·´å ±å‘Šå·²ä¿å­˜è‡³: {report_file}")

        except Exception as e:
            logger.error(f"ç”Ÿæˆè¨“ç·´å ±å‘Šå¤±æ•—: {e}")

    def _generate_recommendations(self, training_result: dict) -> list:
        """ç”Ÿæˆæ”¹é€²å»ºè­°"""
        recommendations = []

        if training_result.get('success'):
            final_metrics = training_result.get('final_metrics', {})
            mae = final_metrics.get('mae', float('inf'))
            r2 = final_metrics.get('r2', -1)

            # çœŸå¯¦åœ–ç‰‡ç‰¹å¾µçš„è©•ä¼°æ¨™æº–
            recommendations.append("âœ… æˆåŠŸä½¿ç”¨çœŸå¯¦é¢éƒ¨ç‰¹å¾µé€²è¡Œè¨“ç·´")

            if mae < 10:
                recommendations.append("ğŸ¯ æ¨¡å‹ç²¾åº¦å„ªç§€ï¼ŒçœŸå¯¦é¢éƒ¨ç‰¹å¾µæ•ˆæœè‰¯å¥½")
            elif mae < 15:
                recommendations.append("ğŸ‘ æ¨¡å‹ç²¾åº¦è‰¯å¥½ï¼Œå»ºè­°å¢åŠ æ›´å¤šè¨“ç·´æ¨£æœ¬")
            elif mae < 20:
                recommendations.append("âš ï¸ æ¨¡å‹ç²¾åº¦ä¸­ç­‰ï¼Œå»ºè­°å„ªåŒ–é¢éƒ¨ç‰¹å¾µæå–æˆ–å¢åŠ è³‡æ–™")
            else:
                recommendations.append("âŒ æ¨¡å‹ç²¾åº¦è¼ƒä½ï¼Œå»ºè­°æª¢æŸ¥é¢éƒ¨æª¢æ¸¬å’Œç‰¹å¾µæå–æµç¨‹")

            # è³‡æ–™é‡åˆ†æ
            dataset_stats = training_result.get('dataset_stats', {})
            num_samples = dataset_stats.get('num_samples', 0)

            if num_samples < 20:
                recommendations.append("ğŸ“ˆ è¨“ç·´æ¨£æœ¬è¼ƒå°‘ï¼Œå»ºè­°æ”¶é›†æ›´å¤šé«˜å“è³ªé¢éƒ¨åœ–ç‰‡")
            elif num_samples < 50:
                recommendations.append("ğŸ“Š è¨“ç·´æ¨£æœ¬ä¸­ç­‰ï¼Œå»ºè­°æŒçºŒå¢åŠ å¤šæ¨£åŒ–çš„é¢éƒ¨è³‡æ–™")
            else:
                recommendations.append("âœ… è¨“ç·´æ¨£æœ¬å……è¶³ï¼Œå¯ä»¥è€ƒæ…®å„ªåŒ–æ¨¡å‹æ¶æ§‹")

            recommendations.append("ğŸ”¬ å»ºè­°èˆ‡æ¨¡æ“¬ç‰¹å¾µçš„çµæœå°æ¯”ï¼Œé©—è­‰çœŸå¯¦ç‰¹å¾µçš„æœ‰æ•ˆæ€§")

        else:
            recommendations.append("âŒ è¨“ç·´å¤±æ•—ï¼Œè«‹æª¢æŸ¥é¢éƒ¨æª¢æ¸¬å™¨å’Œç‰¹å¾µæå–å™¨çš„é…ç½®")
            recommendations.append("ğŸ” å»ºè­°æª¢æŸ¥åœ–ç‰‡å“è³ªå’Œé¢éƒ¨æª¢æ¸¬çš„æˆåŠŸç‡")

        return recommendations

    def test_real_image_model(self, model_path: str, test_samples: int = 3):
        """æ¸¬è©¦çœŸå¯¦åœ–ç‰‡è¨“ç·´çš„æ¨¡å‹"""
        try:
            logger.info(f"æ­£åœ¨æ¸¬è©¦çœŸå¯¦åœ–ç‰‡æ¨¡å‹: {model_path}")

            # è¼‰å…¥æ¨¡å‹
            from ml_pipeline.training.trainer import load_model
            model, config = load_model(model_path)

            # è¼‰å…¥æ¸¬è©¦è³‡æ–™
            dataset_file = self.find_latest_dataset()
            dataset = RealImageDataset(
                data_file=dataset_file,
                image_cache_dir=str(self.image_cache_dir)
            )

            # åŸ·è¡Œæ¸¬è©¦é æ¸¬
            model.eval()
            test_samples = min(test_samples, len(dataset))

            logger.info(f"æ¸¬è©¦ {test_samples} å€‹çœŸå¯¦åœ–ç‰‡æ¨£æœ¬:")

            for i in range(test_samples):
                features, label = dataset[i]
                features = features.unsqueeze(0)  # æ·»åŠ æ‰¹é‡ç¶­åº¦

                # é æ¸¬
                prediction_result = model.predict_lifespan(features)

                actual = float(label[0])
                predicted = prediction_result['predicted_lifespan']
                error = abs(actual - predicted)

                logger.info(f"  æ¨£æœ¬ {i+1} (çœŸå¯¦é¢éƒ¨ç‰¹å¾µ):")
                logger.info(f"    å¯¦éš›å‰©é¤˜å¹´æ•¸: {actual:.1f}")
                logger.info(f"    é æ¸¬å‰©é¤˜å¹´æ•¸: {predicted:.1f}")
                logger.info(f"    èª¤å·®: {error:.1f} å¹´")
                logger.info(f"    ä¿¡å¿ƒåº¦: {prediction_result['confidence']:.2f}")

            logger.info("çœŸå¯¦åœ–ç‰‡æ¨¡å‹æ¸¬è©¦å®Œæˆ!")

        except Exception as e:
            logger.error(f"çœŸå¯¦åœ–ç‰‡æ¨¡å‹æ¸¬è©¦å¤±æ•—: {e}")


def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    parser = argparse.ArgumentParser(description='çœŸå¯¦åœ–ç‰‡å£½å‘½é æ¸¬æ¨¡å‹è¨“ç·´è…³æœ¬')
    parser.add_argument('--mode', choices=['quick', 'default', 'comprehensive'],
                       default='quick', help='è¨“ç·´æ¨¡å¼')
    parser.add_argument('--dataset', type=str, help='æŒ‡å®šè¨“ç·´è³‡æ–™æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--test', type=str, help='æ¸¬è©¦å·²è¨“ç·´çš„çœŸå¯¦åœ–ç‰‡æ¨¡å‹æª”æ¡ˆ')
    parser.add_argument('--analyze-only', action='store_true', help='åƒ…åˆ†æè³‡æ–™é›†ï¼Œä¸é€²è¡Œè¨“ç·´')

    args = parser.parse_args()

    print("å£½å‘½é æ¸¬ç³»çµ± - çœŸå¯¦åœ–ç‰‡æ¨¡å‹è¨“ç·´")
    print("=" * 50)

    try:
        manager = RealImageTrainingManager()

        if args.test:
            # æ¸¬è©¦æ¨¡å¼
            manager.test_real_image_model(args.test)
        elif args.analyze_only:
            # åƒ…åˆ†ææ¨¡å¼
            dataset_file = args.dataset or manager.find_latest_dataset()
            dataset, stats = manager.analyze_real_image_dataset(dataset_file)
            if stats:
                print("\nçœŸå¯¦åœ–ç‰‡ç‰¹å¾µæå–æˆåŠŸ!")
                print(f"è™•ç†æ¨£æœ¬æ•¸: {stats['num_samples']}")
                print(f"ç‰¹å¾µç¶­åº¦: {stats['feature_dim']}")
        else:
            # è¨“ç·´æ¨¡å¼
            result = manager.train_model(mode=args.mode, dataset_file=args.dataset)

            print("=" * 50)
            if result['success']:
                print("ğŸ‰ çœŸå¯¦åœ–ç‰‡æ¨¡å‹è¨“ç·´æˆåŠŸå®Œæˆ!")
                print(f"è¨“ç·´æ™‚é–“: {result.get('training_time_seconds', 0):.1f} ç§’")
                metrics = result.get('final_metrics', {})
                if metrics:
                    print(f"æ¨¡å‹æ€§èƒ½æŒ‡æ¨™ (çœŸå¯¦é¢éƒ¨ç‰¹å¾µ):")
                    print(f"  MAE: {metrics.get('mae', 0):.2f} å¹´")
                    print(f"  RMSE: {metrics.get('rmse', 0):.2f} å¹´")
                    print(f"  RÂ²: {metrics.get('r2', 0):.3f}")
                print(f"æ¨¡å‹å·²ä¿å­˜è‡³: {result.get('model_path', 'N/A')}")
            else:
                print("âŒ çœŸå¯¦åœ–ç‰‡æ¨¡å‹è¨“ç·´å¤±æ•—!")
                print(f"éŒ¯èª¤: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
                return 1

    except KeyboardInterrupt:
        print("\nç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
        return 1
    except Exception as e:
        print(f"\nç¨‹åºåŸ·è¡Œå¤±æ•—: {e}")
        return 1

    return 0


if __name__ == "__main__":
    sys.exit(main())